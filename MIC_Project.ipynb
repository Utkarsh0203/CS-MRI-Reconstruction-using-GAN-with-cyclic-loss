{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIC_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O98AR0CAZXam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from PIL import Image \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms,utils,datasets\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ScYPGYkWrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpLKC07F-ISV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB5Ie0-eP91A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MASK = 'radial'\n",
        "MASK_PERCENT = '10'\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "\t\ttransforms.ToPILImage(),\n",
        "\t\ttransforms.RandomResizedCrop(244),\n",
        "\t\ttransforms.Resize(256),\n",
        "\t\ttransforms.RandomHorizontalFlip(),\n",
        "\t\ttransforms.RandomVerticalFlip(),\n",
        "\t\ttransforms.RandomRotation(90, fill=0),\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t\t# mk3(mask)\n",
        "\t])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtFq02rrSqv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RF(image, mask, batch = False):\t#both image and mask arg are (2,256,256) tensors\n",
        "  if not batch:\n",
        "    image = image.permute(1,2,0)\n",
        "    mask = mask.permute(1,2,0)\n",
        "    frq = torch.fft(image, 2)\n",
        "    res = torch.mul(frq, mask)\n",
        "    res = res.permute(2,0,1)\n",
        "    return res\n",
        "  else:\n",
        "    image = image.permute(0,2,3,1)\n",
        "    mask = mask.permute(0,2,3,1)\n",
        "    frq = torch.fft(image, 2)\n",
        "    res = torch.mul(frq, mask)\n",
        "    res = res.permute(0,3,1,2)\n",
        "    return res\n",
        "\n",
        "def FhRh(frq, batch = False):\n",
        "  if not batch:\n",
        "    frq = frq.permute(1,2,0)\n",
        "    res = torch.ifft(frq, 2)\n",
        "    res = torch.clamp(res, min=-1, max=1)\n",
        "    res = res.permute(2,0,1)\n",
        "    return res\n",
        "  else:\n",
        "    frq = frq.permute(0,2,3,1)\n",
        "    res = torch.ifft(frq, 2)\n",
        "    res = torch.clamp(res, min=-1, max=1)\n",
        "    res = res.permute(0,3,1,2)\n",
        "    return res"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A2D5ntiRym1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_train(Dataset):\n",
        "\tdef __init__(self, data_dir='/content/drive/My Drive/CS736 Project/data/brain/db_train', mask_path='/content/drive/My Drive/CS736 Project/data/mask/{}/{}_{}.tif'.format(MASK, MASK, MASK_PERCENT), transform=train_transforms):\n",
        "\t\tself.us_train_data = torch.zeros(100, 2, 256, 256)\n",
        "\t\tself.transform=transform\n",
        "\t\tself.mask = cv2.imread(mask_path)\n",
        "\t\tself.mask = cv2.cvtColor(self.mask, cv2.COLOR_BGR2GRAY)/255\n",
        "\t\tself.mask2 = torch.zeros(2,256,256)\n",
        "\t\tself.mask2[0] = torch.Tensor(self.mask)\n",
        "\t\ti=0\n",
        "\t\tfor filename in os.listdir(data_dir):\n",
        "\t\t\timage = cv2.imread('{}/{}'.format(data_dir, filename))\n",
        "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t# image = 2*(image/255) - 1\n",
        "\t\t\tself.us_train_data[i,0] = torch.Tensor(image)\n",
        "\t\t\ti = i+1\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.us_train_data)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tsample = self.us_train_data[idx,0]\n",
        "\t\tself.us_train_data[idx,0] = (self.transform(sample))*2-1\n",
        "\t\t# sample = sample*2 -1\n",
        "\t\timage = self.us_train_data[idx]\n",
        "\t\tfrq = RF(image, self.mask2)\n",
        "\t\tres = FhRh(frq)\n",
        "\t\tfin = tuple([image,frq,res])\n",
        "\t\treturn fin"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-5NWqLwR38u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = Dataset_train()\n",
        "dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FDrS3kANttR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualCell(nn.Module):\n",
        "  def __init__(self, n_filters):\n",
        "    super(ResidualCell, self).__init__()\n",
        "    #Residual connections, (H,W) remain same \n",
        "    self.conv_i = nn.Conv2d(n_filters, n_filters, (3,3), 1, 1) #Why is this layer needed?\n",
        "    self.conv_m = nn.Conv2d(n_filters, int(n_filters/2), (3,3), 1, 1)\n",
        "    self.conv_o = nn.Conv2d(int(n_filters/2), n_filters, (3,3), 1, 1)\n",
        "    \n",
        "    self.res_net = nn.Sequential(self.conv_i, nn.ReLU(), self.conv_m, nn.ReLU(), self.conv_o, nn.ReLU())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x+self.res_net(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-tLM5gNLgRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderCell(nn.Module):\n",
        "  def __init__(self, n_in, n_res, pad=0):\n",
        "    super(EncoderCell, self).__init__()\n",
        "\n",
        "    self.conv_a = nn.Conv2d(n_in, n_res, (3,3), 2, padding=pad)\n",
        "    self.res = ResidualCell(n_res)\n",
        "    self.conv_b = nn.Conv2d(n_res, n_res, (3,3), 1)\n",
        "\n",
        "    self.encoder = nn.Sequential(self.conv_a, nn.ReLU(), self.res, self.conv_b, nn.ReLU())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.encoder(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tofchbZ3NYSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderCell(nn.Module):\n",
        "  def __init__(self, n_in, n_res, pad=0):\n",
        "    super(DecoderCell, self).__init__()\n",
        "\n",
        "    self.deconv_a = nn.ConvTranspose2d(n_in, n_res, (3,3), 1)\n",
        "    self.res = ResidualCell(n_res)\n",
        "    self.deconv_b = nn.ConvTranspose2d(n_res, n_res, (3,3), 2, output_padding=pad)\n",
        "\n",
        "    self.decoder = nn.Sequential(self.deconv_a, nn.ReLU(), self.res, self.deconv_b, nn.ReLU())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.decoder(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmCTpEpuaKl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubGenerator(nn.Module):\n",
        "  \"\"\"\n",
        "  Input: Zero filling imperfect reconstruction by inverse of undersampled fourier transform\n",
        "  Output: Full image which (should) belongs to the set of all possible perfect reconstructions\n",
        "  \"\"\"\n",
        "  def __init__(self, n):\n",
        "    super(SubGenerator, self).__init__()\n",
        "    #Input channels = 2 \n",
        "\n",
        "    #ConvEncoder\n",
        "    self.ec0 = EncoderCell(2,n)\n",
        "    self.ec1 = EncoderCell(n,2*n)\n",
        "    self.ec2 = EncoderCell(2*n,4*n)\n",
        "    self.ec3 = EncoderCell(4*n,8*n)\n",
        "\n",
        "    #ConvDecoder\n",
        "    self.dc3 = DecoderCell(8*n,4*n)\n",
        "    self.dc2 = DecoderCell(4*n,2*n,1)\n",
        "    self.dc1 = DecoderCell(2*n,n)\n",
        "    self.dc0 = DecoderCell(n,n,1)\n",
        "\n",
        "    #Output \n",
        "    self.out = nn.Sequential(nn.Conv2d(n,2,(3,3),1,1), #Real and Complex channels as outputs?\n",
        "                             nn.Tanh())\n",
        "\n",
        "  def forward(self, x):\n",
        "    #With Residual Connections\n",
        "    # print(x.shape)\n",
        "    e0 = self.ec0(x)\n",
        "    # print(e0.shape)\n",
        "    e1 = self.ec1(e0)\n",
        "    # print(e1.shape)\n",
        "    e2 = self.ec2(e1)\n",
        "    # print(e2.shape)\n",
        "    e3 = self.ec3(e2)\n",
        "    # print(e3.shape)\n",
        "\n",
        "    d3 = self.dc3(e3)\n",
        "    # print(d3.shape)\n",
        "    d2 = self.dc2(d3+e2)\n",
        "    # print(d2.shape)\n",
        "    d1 = self.dc1(d2+e1)\n",
        "    # print(d1.shape)\n",
        "    d0 = self.dc0(d1+e0)\n",
        "    # print(d0.shape)\n",
        "\n",
        "    y = self.out(d0)\n",
        "    # print(y.shape)\n",
        "\n",
        "    return y\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jYZnzsVfW3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.reconGAN = SubGenerator(n)\n",
        "    self.refineGAN = SubGenerator(n)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = x+self.reconGAN(x)\n",
        "    z = y+self.refineGAN(y) \n",
        "    return (y,z)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyMfLT91uiX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    #Downsample Layers\n",
        "\n",
        "    self.ec0 = EncoderCell(2,n)\n",
        "    self.ec1 = EncoderCell(n,2*n)\n",
        "    self.ec2 = EncoderCell(2*n,4*n)\n",
        "    self.ec3 = EncoderCell(4*n,8*n)\n",
        "\n",
        "    #Probability Output\n",
        "    self.downsampler = nn.Sequential(self.ec0, self.ec1, self.ec2, self.ec3)\n",
        "    #Abstract latent space size in final layer?\n",
        "    # self.out = nn.Sequential(nn.Conv2d(8*n,1,(11,11), 1), nn.Sigmoid()) #With BCELoss (not numerically stable)\n",
        "    self.out = nn.Sequential(nn.Conv2d(8*n,1,(11,11), 1)) #With stable bceloss with logits\n",
        "\n",
        "  def forward(self, x):\n",
        "    d = self.downsampler(x)\n",
        "    y = self.out(d)\n",
        "    # return torch.squeeze(y)\n",
        "    return y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHZlArbZrLbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1546fe6-05cc-40d0-e9b6-490f27117f8b"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "epochs = 5\n",
        "# batch_size = 100\n",
        "num_filters = 64\n",
        "lr = 0.0001\n",
        "\n",
        "criterion_D = nn.BCEWithLogitsLoss()\n",
        "criterionG_image = nn.L1Loss()\n",
        "criterionG_freq = nn.L1Loss()\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "alpha = 1.0\n",
        "gamma = 10.0\n",
        "\n",
        "netG = Generator(num_filters)\n",
        "netD = Discriminator(num_filters)\n",
        "\n",
        "opt_D = optim.Adam(netD.parameters(), lr=lr)\n",
        "opt_G = optim.Adam(netG.parameters(), lr=lr)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3njYnRCFVIsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_mask = train_data.mask2.repeat(batch_size,1,1,1)\n",
        "batch_mask = batch_mask.to(device)\n",
        "# mask.shape"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6-nfPBAge2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(netG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcPxb_sugg7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJnbEV0bo6Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5746422-712b-455c-d0bf-1083f2d104ee"
      },
      "source": [
        "G_parameters = filter(lambda p: p.requires_grad, netG.parameters())\n",
        "Gparams = sum([np.prod(p.size()) for p in G_parameters])\n",
        "print(\"Generator Parameters:\",Gparams)\n",
        "D_parameters = filter(lambda p: p.requires_grad, netD.parameters())\n",
        "Dparams = sum([np.prod(p.size()) for p in D_parameters])\n",
        "print(\"Discriminator Parameters:\",Dparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator Parameters: 29951428\n",
            "Discriminator Parameters: 11016033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM3trsFsMtDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxu8NnrLXGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generated_Images = []\n",
        "G_loss_img = []\n",
        "G_loss_freq = []\n",
        "G_loss_adv = []\n",
        "G_loss_total = []\n",
        "\n",
        "D_loss_real = []\n",
        "D_loss_fake = []\n",
        "D_loss_total = []\n",
        "\n",
        "netD.to(device)\n",
        "netD.train()\n",
        "netG.to(device)\n",
        "netG.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu6JYjPYUfFZ",
        "colab_type": "text"
      },
      "source": [
        "Training:<br>\n",
        "We will train the D and G in an alternating fashion. <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fanDG1sOTdEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "outputId": "35a3ea0c-2993-49af-c390-da751eda5f9d"
      },
      "source": [
        "# def GANvtrain(netG, netD, model_params, hyper_params criterions, optimizers, dataloader)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, im_tuple in enumerate(dataloader, 0):\n",
        "\n",
        "    full_image_batch = im_tuple[0].to(device)\n",
        "    us_kspace_batch = im_tuple[1].to(device)\n",
        "    zf_recon_batch = im_tuple[2].to(device)\n",
        "\n",
        "    gen_full_image_batch = netG(zf_recon_batch)[1]\n",
        "    # print(\"Generated Img Batch\")\n",
        "    real_logits = netD(full_image_batch).view(-1)\n",
        "    fake_logitsD = netD(gen_full_image_batch.detach()).view(-1)\n",
        "\n",
        "    # print(\"Computed Real and Fake Logits\")\n",
        "    \n",
        "    # recon_image_batch = netG(torch.ifft(mask*torch.fft(full_image_batch.permute([0,2,3,1]),2)).permute([0,3,1,2]))[1]\n",
        "    # recon_kspace_batch = (mask*torch.fft(netG(torch.ifft(us_kspace_batch.permute([0,2,3,1]),2).permute([0,3,1,2]))[1].permute([0,2,3,1]),2)).permute([0,3,1,2])\n",
        "    # recon_image_batch = netG(FhRh(RF(full_image_batch, batch_mask, batch = True), batch = True))[0]\n",
        "    # recon_kspace_batch = RF(netG(FhRh(us_kspace_batch, batch=True))[0], batch_mask, batch = True)\n",
        "    \n",
        "    \n",
        "    #Discriminator Training \n",
        "    # real_targets = torch.full([batch_size], real_label, device=device)\n",
        "    # fake_targets = torch.full([batch_size], real_label, device=device)\n",
        "    opt_D.zero_grad()\n",
        "    \n",
        "    real_d_loss = criterion_D(real_logits, torch.full([batch_size], real_label, device=device))\n",
        "    D_loss_real.append(real_d_loss)\n",
        "    real_d_loss.backward()\n",
        "\n",
        "    fake_d_loss = criterion_D(fake_logitsD, torch.full([batch_size], fake_label, device=device))\n",
        "    D_loss_fake.append(fake_d_loss)\n",
        "    fake_d_loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      d_loss_total = real_d_loss+fake_d_loss\n",
        "    D_loss_total.append(d_loss_total)\n",
        "\n",
        "    opt_D.step()\n",
        "\n",
        "    #Generator Training\n",
        "    # real_targets = torch.full([batch_size], real_label, device=device)\n",
        "    # fake_targets = torch.full([batch_size], real_label, device=device)\n",
        "    opt_G.zero_grad()\n",
        "\n",
        "    fake_logitsG = netD(gen_full_image_batch).view(-1)\n",
        "    adv_g_loss = criterion_D(fake_logitsG, torch.full([batch_size], real_label, device=device))\n",
        "    G_loss_adv.append(adv_g_loss)\n",
        "    adv_g_loss.backward()\n",
        "\n",
        "    recon_image_batch = netG(zf_recon_batch)[1] #Because same underlying image\n",
        "    g_image_loss = alpha*criterionG_image(recon_image_batch,full_image_batch)\n",
        "    G_loss_img.append(g_image_loss)\n",
        "    g_image_loss.backward()\n",
        "\n",
        "    recon_kspace_batch = RF(netG(zf_recon_batch)[1], batch_mask, batch = True) #Because same underlying image\n",
        "    g_freq_loss = gamma*criterionG_freq(recon_kspace_batch,us_kspace_batch)\n",
        "    G_loss_freq.append(g_freq_loss)\n",
        "    g_freq_loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      g_loss_total = adv_g_loss+g_image_loss+g_freq_loss\n",
        "    G_loss_total.append(g_loss_total)\n",
        "\n",
        "    opt_G.step()   \n",
        "\n",
        "    print(\"Epoch:\", epoch, \"Batch:\", batch_idx, \"G Loss:\", float('%.2f' % g_loss_total.data.tolist()), \"D Loss:\", float('%.2f' % d_loss_total.data.tolist()))\n",
        "  \n",
        "  #Write Function for imshow(recon_image_batch[0]) to display image every epoch or Generated_Images.append(recon_image_batch[0])\n",
        "    \n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Batch: 0 G Loss: 1.21 D Loss: 1.39\n",
            "Epoch: 0 Batch: 1 G Loss: 1.19 D Loss: 1.39\n",
            "Epoch: 0 Batch: 2 G Loss: 1.15 D Loss: 1.39\n",
            "Epoch: 0 Batch: 3 G Loss: 1.13 D Loss: 1.39\n",
            "Epoch: 0 Batch: 4 G Loss: 1.15 D Loss: 1.39\n",
            "Epoch: 0 Batch: 5 G Loss: 1.18 D Loss: 1.38\n",
            "Epoch: 0 Batch: 6 G Loss: 1.19 D Loss: 1.38\n",
            "Epoch: 0 Batch: 7 G Loss: 1.18 D Loss: 1.38\n",
            "Epoch: 0 Batch: 8 G Loss: 1.11 D Loss: 1.37\n",
            "Epoch: 0 Batch: 9 G Loss: 1.13 D Loss: 1.35\n",
            "Epoch: 1 Batch: 0 G Loss: 1.32 D Loss: 1.31\n",
            "Epoch: 1 Batch: 1 G Loss: 1.39 D Loss: 1.26\n",
            "Epoch: 1 Batch: 2 G Loss: 1.24 D Loss: 1.22\n",
            "Epoch: 1 Batch: 3 G Loss: 1.31 D Loss: 1.15\n",
            "Epoch: 1 Batch: 4 G Loss: 1.73 D Loss: 1.05\n",
            "Epoch: 1 Batch: 5 G Loss: 1.85 D Loss: 0.92\n",
            "Epoch: 1 Batch: 6 G Loss: 1.56 D Loss: 0.69\n",
            "Epoch: 1 Batch: 7 G Loss: 2.38 D Loss: 0.59\n",
            "Epoch: 1 Batch: 8 G Loss: 3.45 D Loss: 0.35\n",
            "Epoch: 1 Batch: 9 G Loss: 5.15 D Loss: 0.61\n",
            "Epoch: 2 Batch: 0 G Loss: 4.47 D Loss: 4.2\n",
            "Epoch: 2 Batch: 1 G Loss: 2.97 D Loss: 2.88\n",
            "Epoch: 2 Batch: 2 G Loss: 1.17 D Loss: 0.83\n",
            "Epoch: 2 Batch: 3 G Loss: 1.66 D Loss: 0.76\n",
            "Epoch: 2 Batch: 4 G Loss: 1.97 D Loss: 1.76\n",
            "Epoch: 2 Batch: 5 G Loss: 2.33 D Loss: 0.59\n",
            "Epoch: 2 Batch: 6 G Loss: 2.15 D Loss: 1.25\n",
            "Epoch: 2 Batch: 7 G Loss: 2.05 D Loss: 1.29\n",
            "Epoch: 2 Batch: 8 G Loss: 1.91 D Loss: 1.14\n",
            "Epoch: 2 Batch: 9 G Loss: 1.65 D Loss: 1.2\n",
            "Epoch: 3 Batch: 0 G Loss: 1.61 D Loss: 1.16\n",
            "Epoch: 3 Batch: 1 G Loss: 1.29 D Loss: 1.1\n",
            "Epoch: 3 Batch: 2 G Loss: 1.17 D Loss: 0.97\n",
            "Epoch: 3 Batch: 3 G Loss: 0.74 D Loss: 2.36\n",
            "Epoch: 3 Batch: 4 G Loss: 0.74 D Loss: 4.37\n",
            "Epoch: 3 Batch: 5 G Loss: 0.98 D Loss: 5.51\n",
            "Epoch: 3 Batch: 6 G Loss: 0.93 D Loss: 3.64\n",
            "Epoch: 3 Batch: 7 G Loss: 1.11 D Loss: 2.37\n",
            "Epoch: 3 Batch: 8 G Loss: 1.21 D Loss: 1.74\n",
            "Epoch: 3 Batch: 9 G Loss: 1.29 D Loss: 1.53\n",
            "Epoch: 4 Batch: 0 G Loss: 1.4 D Loss: 1.37\n",
            "Epoch: 4 Batch: 1 G Loss: 1.42 D Loss: 1.31\n",
            "Epoch: 4 Batch: 2 G Loss: 1.51 D Loss: 1.3\n",
            "Epoch: 4 Batch: 3 G Loss: 1.44 D Loss: 1.29\n",
            "Epoch: 4 Batch: 4 G Loss: 1.48 D Loss: 1.28\n",
            "Epoch: 4 Batch: 5 G Loss: 1.49 D Loss: 1.28\n",
            "Epoch: 4 Batch: 6 G Loss: 1.44 D Loss: 1.28\n",
            "Epoch: 4 Batch: 7 G Loss: 1.48 D Loss: 1.25\n",
            "Epoch: 4 Batch: 8 G Loss: 1.45 D Loss: 1.23\n",
            "Epoch: 4 Batch: 9 G Loss: 1.46 D Loss: 1.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi9Wp0vi92ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9fb1d54-a11f-47c2-9079-916a9f4d225d"
      },
      "source": [
        "print(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}