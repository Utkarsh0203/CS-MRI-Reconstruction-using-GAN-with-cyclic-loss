{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CS_MRI_GAN_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O98AR0CAZXam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from PIL import Image \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms,utils,datasets\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ScYPGYkWrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpLKC07F-ISV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB5Ie0-eP91A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MASK = 'radial'\n",
        "MASK_PERCENT = '20'\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "\t\t# transforms.ToPILImage(),\n",
        "\t\ttransforms.RandomHorizontalFlip(),\n",
        "\t\ttransforms.RandomVerticalFlip(),\n",
        "\t\ttransforms.RandomRotation(90, fill=0),\n",
        "\t\ttransforms.RandomCrop(244),\n",
        "\t\ttransforms.Pad(6),\n",
        "\t\ttransforms.ToTensor()\n",
        "\t])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtFq02rrSqv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RF(image, mask, batch = False):\t#both image and mask arg are (2,256,256) tensors\n",
        "  if not batch:\n",
        "    image = image.permute(1,2,0)\n",
        "    mask = mask.permute(1,2,0)\n",
        "    frq = torch.fft(image, 2)\n",
        "    res = torch.mul(frq, mask)\n",
        "    res = res.permute(2,0,1)\n",
        "    return res\n",
        "  else:\n",
        "    image = image.permute(0,2,3,1)\n",
        "    mask = mask.permute(0,2,3,1)\n",
        "    frq = torch.fft(image, 2)\n",
        "    res = torch.mul(frq, mask)\n",
        "    res = res.permute(0,3,1,2)\n",
        "    return res\n",
        "\n",
        "def FhRh(frq, batch = False):\n",
        "  if not batch:\n",
        "    frq = frq.permute(1,2,0)\n",
        "    res = torch.ifft(frq, 2)\n",
        "    res = torch.clamp(res, min=-1, max=1)\n",
        "    res = res.permute(2,0,1)\n",
        "    return res\n",
        "  else:\n",
        "    frq = frq.permute(0,2,3,1)\n",
        "    res = torch.ifft(frq, 2)\n",
        "    res = torch.clamp(res, min=-1, max=1)\n",
        "    res = res.permute(0,3,1,2)\n",
        "    return res\n",
        "  \n",
        "def displayTensor(tnsr, name=\"image\"):\t#input tensor is (2,256,256)\n",
        "  real = tnsr[0]\n",
        "  image = (real+1)*255/2\n",
        "  image = np.array(image, dtype=\"uint8\")\n",
        "  plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
        "  # cv2.imshow(name, image)\n",
        "  # cv2.waitKey(0)\n",
        "  # cv2.destroyAllWindows()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A2D5ntiRym1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_train(Dataset):\n",
        "\tdef __init__(self, data_dir='/content/drive/My Drive/CS736 Project/data/brain/db_train', mask_path='/content/drive/My Drive/CS736 Project/data/mask/{}/{}_{}.tif'.format(MASK, MASK, MASK_PERCENT), transform=train_transforms):\n",
        "\t\tself.us_train_data = []\n",
        "\t\tself.transform=transform\n",
        "\t\tself.mask = cv2.imread(mask_path)\n",
        "\t\tself.mask = cv2.cvtColor(self.mask, cv2.COLOR_BGR2GRAY)/255\n",
        "\t\tself.mask2 = torch.zeros(2,256,256)\n",
        "\t\tself.mask2[0] = torch.Tensor(self.mask)\n",
        "\t\tself.mask2[1] = torch.Tensor(self.mask)\n",
        "\t\ti=0\n",
        "\t\tfor filename in os.listdir(data_dir):\n",
        "\t\t\timage = Image.open('{}/{}'.format(data_dir, filename))\n",
        "\t\t\t# image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t# image = 2*(image/255) - 1\n",
        "\t\t\tself.us_train_data.append(image)\n",
        "\t\t\ti = i+1\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.us_train_data)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tsample = self.us_train_data[idx]\n",
        "\t\tsample2 = (self.transform(sample))*2-1\n",
        "\t\timage = torch.zeros(2,256,256)\n",
        "\t\timage[0] = sample2\n",
        "\t\timage[1] = image[1]-1\n",
        "\t\t# self.us_train_data[idx,0] = (self.transform(sample))*2-1\n",
        "\t\t# sample = sample*2 -1\n",
        "\t\t# image = self.us_train_data[idx]\n",
        "\t\tfrq = RF(image, self.mask2)\n",
        "\t\tres = FhRh(frq)\n",
        "\t\tfin = tuple([image,frq,res])\n",
        "\t\treturn fin"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-5NWqLwR38u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = Dataset_train()\n",
        "dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1ZRmchDFfW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef0f2bc8-8253-47bb-c2af-c787189433b1"
      },
      "source": [
        "fre1 = train_data[0][2]\n",
        "print(torch.min(fre1),torch.max(fre1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-1.) tensor(0.7990)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FDrS3kANttR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualCell(nn.Module):\n",
        "  def __init__(self, n_filters):\n",
        "    super(ResidualCell, self).__init__()\n",
        "    #Residual connections, (H,W) remain same \n",
        "    self.conv_i = nn.Conv2d(n_filters, n_filters, (3,3), 1, 1) #Why is this layer needed?\n",
        "    self.conv_m = nn.Conv2d(n_filters, int(n_filters/2), (3,3), 1, 1)\n",
        "    self.conv_o = nn.Conv2d(int(n_filters/2), n_filters, (3,3), 1, 1)\n",
        "    \n",
        "    self.res_net = nn.Sequential(self.conv_i, nn.BatchNorm2d(n_filters), nn.ReLU(),\n",
        "                                 self.conv_m, nn.BatchNorm2d(int(n_filters/2)), nn.ReLU(),\n",
        "                                 self.conv_o, nn.BatchNorm2d(n_filters), nn.ReLU())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x+self.res_net(x)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-tLM5gNLgRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderCell(nn.Module):\n",
        "  def __init__(self, n_in, n_res, pad=0, leaky = False):\n",
        "    super(EncoderCell, self).__init__()\n",
        "\n",
        "    self.conv_a = nn.Conv2d(n_in, n_res, (3,3), 2, padding=pad)\n",
        "    self.res = ResidualCell(n_res)\n",
        "    self.conv_b = nn.Conv2d(n_res, n_res, (3,3), 1)\n",
        "\n",
        "    if not leaky:\n",
        "      self.encoder = nn.Sequential(self.conv_a,  nn.BatchNorm2d(n_res), nn.ReLU(), \n",
        "                                   self.res, \n",
        "                                   self.conv_b,  nn.BatchNorm2d(n_res), nn.ReLU())\n",
        "    else:\n",
        "      self.encoder = nn.Sequential(self.conv_a,  nn.BatchNorm2d(n_res), nn.LeakyReLU(0.2),\n",
        "                                   self.res, \n",
        "                                   self.conv_b,  nn.BatchNorm2d(n_res), nn.LeakyReLU(0.2))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.encoder(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tofchbZ3NYSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderCell(nn.Module):\n",
        "  def __init__(self, n_in, n_res, pad=0):\n",
        "    super(DecoderCell, self).__init__()\n",
        "\n",
        "    self.deconv_a = nn.ConvTranspose2d(n_in, n_res, (3,3), 1)\n",
        "    self.res = ResidualCell(n_res)\n",
        "    self.deconv_b = nn.ConvTranspose2d(n_res, n_res, (3,3), 2, output_padding=pad)\n",
        "\n",
        "    self.decoder = nn.Sequential(self.deconv_a, nn.BatchNorm2d(n_res), nn.ReLU(), \n",
        "                                 self.res, \n",
        "                                 self.deconv_b, nn.BatchNorm2d(n_res), nn.ReLU())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.decoder(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmCTpEpuaKl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubGenerator(nn.Module):\n",
        "  \"\"\"\n",
        "  Input: Zero filling imperfect reconstruction by inverse of undersampled fourier transform\n",
        "  Output: Full image which (should) belongs to the set of all possible perfect reconstructions\n",
        "  \"\"\"\n",
        "  def __init__(self, n):\n",
        "    super(SubGenerator, self).__init__()\n",
        "    #Input channels = 2 \n",
        "\n",
        "    #ConvEncoder\n",
        "    self.ec0 = EncoderCell(2,n)\n",
        "    self.ec1 = EncoderCell(n,2*n)\n",
        "    self.ec2 = EncoderCell(2*n,4*n)\n",
        "    self.ec3 = EncoderCell(4*n,8*n)\n",
        "\n",
        "    #ConvDecoder\n",
        "    self.dc3 = DecoderCell(8*n,4*n)\n",
        "    self.dc2 = DecoderCell(4*n,2*n,1)\n",
        "    self.dc1 = DecoderCell(2*n,n)\n",
        "    self.dc0 = DecoderCell(n,n,1)\n",
        "\n",
        "    #Output \n",
        "    self.out = nn.Sequential(nn.Conv2d(n,2,(3,3),1,1), #Real and Complex channels as outputs?\n",
        "                             nn.Tanh())\n",
        "\n",
        "  def forward(self, x):\n",
        "    #With Residual Connections\n",
        "    # print(x.shape)\n",
        "    e0 = self.ec0(x)\n",
        "    # print(e0.shape)\n",
        "    e1 = self.ec1(e0)\n",
        "    # print(e1.shape)\n",
        "    e2 = self.ec2(e1)\n",
        "    # print(e2.shape)\n",
        "    e3 = self.ec3(e2)\n",
        "    # print(e3.shape)\n",
        "\n",
        "    d3 = self.dc3(e3)\n",
        "    # print(d3.shape)\n",
        "    d2 = self.dc2(d3+e2)\n",
        "    # print(d2.shape)\n",
        "    d1 = self.dc1(d2+e1)\n",
        "    # print(d1.shape)\n",
        "    d0 = self.dc0(d1+e0)\n",
        "    # print(d0.shape)\n",
        "\n",
        "    y = self.out(d0)\n",
        "    # print(y.shape)\n",
        "\n",
        "    return y\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jYZnzsVfW3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.reconGAN = SubGenerator(n)\n",
        "    self.refineGAN = SubGenerator(n)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = x+self.reconGAN(x)\n",
        "    z = y+self.refineGAN(y)\n",
        "    return (y,z)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyMfLT91uiX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    #Downsample Layers\n",
        "\n",
        "    self.ec0 = EncoderCell(2,n,leaky=True)\n",
        "    self.ec1 = EncoderCell(n,2*n,leaky=True)\n",
        "    self.ec2 = EncoderCell(2*n,4*n,leaky=True)\n",
        "    self.ec3 = EncoderCell(4*n,8*n,leaky=True)\n",
        "\n",
        "    #Probability Output\n",
        "    self.downsampler = nn.Sequential(self.ec0, self.ec1, self.ec2, self.ec3)\n",
        "    #Abstract latent space size in final layer?\n",
        "    # self.out = nn.Sequential(nn.Conv2d(8*n,1,(11,11), 1), nn.Sigmoid()) #With BCELoss (not numerically stable)\n",
        "    self.out = nn.Sequential(nn.Conv2d(8*n,1,(11,11), 1)) #With stable bceloss with logits\n",
        "\n",
        "  def forward(self, x):\n",
        "    d = self.downsampler(x)\n",
        "    y = self.out(d)\n",
        "    # return torch.squeeze(y)\n",
        "    return y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS2Qb91uw8IP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHZlArbZrLbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d6359d1-f2e5-425a-b321-0ce29e2ce5b7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "epochs = 100\n",
        "# batch_size = 100\n",
        "num_filters = 64\n",
        "lr = 0.00001\n",
        "\n",
        "criterion_D = nn.BCEWithLogitsLoss()\n",
        "criterionG_image = nn.MSELoss()\n",
        "criterionG_freq = nn.MSELoss()\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "alpha = 1.0\n",
        "gamma = 10.0\n",
        "\n",
        "netG = Generator(num_filters)\n",
        "netD = Discriminator(num_filters)\n",
        "\n",
        "opt_D = optim.Adam(netD.parameters(), lr=lr)\n",
        "opt_G = optim.Adam(netG.parameters(), lr=lr)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3njYnRCFVIsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_mask = train_data.mask2.repeat(batch_size,1,1,1)\n",
        "batch_mask = batch_mask.to(device)\n",
        "# mask.shape"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6-nfPBAge2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(netG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcPxb_sugg7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJnbEV0bo6Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e8def828-3c50-4c40-9fff-871427df208e"
      },
      "source": [
        "G_parameters = filter(lambda p: p.requires_grad, netG.parameters())\n",
        "Gparams = sum([np.prod(p.size()) for p in G_parameters])\n",
        "print(\"Generator Parameters:\",Gparams)\n",
        "D_parameters = filter(lambda p: p.requires_grad, netD.parameters())\n",
        "Dparams = sum([np.prod(p.size()) for p in D_parameters])\n",
        "print(\"Discriminator Parameters:\",Dparams)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator Parameters: 29977924\n",
            "Discriminator Parameters: 11024673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM3trsFsMtDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxu8NnrLXGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generated_Images = []\n",
        "G_loss_img = []\n",
        "G_loss_freq = []\n",
        "G_loss_adv = []\n",
        "G_loss_total = []\n",
        "\n",
        "G_loss_img_epoch = []\n",
        "G_loss_freq_epoch = []\n",
        "G_loss_adv_epoch = []\n",
        "G_loss_total_epoch = []\n",
        "\n",
        "D_loss_real = []\n",
        "D_loss_fake = []\n",
        "D_loss_total = []\n",
        "\n",
        "netD.apply(weights_init)\n",
        "netD.to(device)\n",
        "netD.train()\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netG.to(device)\n",
        "netG.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu6JYjPYUfFZ",
        "colab_type": "text"
      },
      "source": [
        "Training:<br>\n",
        "We will train the D and G in an alternating fashion. <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fanDG1sOTdEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def GANvtrain(netG, netD, model_params, hyper_params criterions, optimizers, dataloader)\n",
        "image_recon=[]\n",
        "loss_arr=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, im_tuple in enumerate(dataloader, 0):\n",
        "\n",
        "    full_image_batch = im_tuple[0].to(device)\n",
        "    us_kspace_batch = im_tuple[1].to(device)\n",
        "    zf_recon_batch = im_tuple[2].to(device)\n",
        "\n",
        "    \n",
        "    # recon_image_batch = netG(torch.ifft(mask*torch.fft(full_image_batch.permute([0,2,3,1]),2)).permute([0,3,1,2]))[1]\n",
        "    # recon_kspace_batch = (mask*torch.fft(netG(torch.ifft(us_kspace_batch.permute([0,2,3,1]),2).permute([0,3,1,2]))[1].permute([0,2,3,1]),2)).permute([0,3,1,2])\n",
        "    # recon_image_batch = netG(FhRh(RF(full_image_batch, batch_mask, batch = True), batch = True))[0]\n",
        "    # recon_kspace_batch = RF(netG(FhRh(us_kspace_batch, batch=True))[0], batch_mask, batch = True)\n",
        "    \n",
        "    \n",
        "    #Discriminator Training \n",
        "    # real_targets = torch.full([batch_size], real_label, device=device)\n",
        "    # fake_targets = torch.full([batch_size], real_label, device=device)\n",
        "\n",
        "    opt_D.zero_grad()#Different mini batches for real and fake targets\n",
        "    \n",
        "    real_logits = netD(full_image_batch).view(-1)\n",
        "    real_d_loss = criterion_D(real_logits, torch.full([batch_size], real_label, device=device))\n",
        "    D_loss_real.append(real_d_loss)\n",
        "    real_d_loss.backward()\n",
        "\n",
        "    gen_full_image_batch = netG(zf_recon_batch)[1]\n",
        "    fake_logitsD = netD(gen_full_image_batch.detach()).view(-1)\n",
        "    fake_d_loss = criterion_D(fake_logitsD, torch.full([batch_size], fake_label, device=device))\n",
        "    D_loss_fake.append(fake_d_loss)\n",
        "    fake_d_loss.backward()\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    d_loss_total = real_d_loss+fake_d_loss\n",
        "    D_loss_total.append(d_loss_total.data)\n",
        "\n",
        "    opt_D.step()\n",
        "\n",
        "    #Generator Training\n",
        "    # real_targets = torch.full([batch_size], real_label, device=device)\n",
        "    # fake_targets = torch.full([batch_size], real_label, device=device)\n",
        "    opt_G.zero_grad()\n",
        "\n",
        "    fake_logitsG = netD(gen_full_image_batch).view(-1)\n",
        "    adv_g_loss = criterion_D(fake_logitsG, torch.full([batch_size], real_label, device=device))\n",
        "    G_loss_adv.append(adv_g_loss)\n",
        "    adv_g_loss.backward()\n",
        "\n",
        "    recon_image_batch = netG(zf_recon_batch)[1] #Because same underlying image\n",
        "    g_image_loss = gamma*criterionG_image(recon_image_batch,full_image_batch)\n",
        "    G_loss_img.append(g_image_loss)\n",
        "    g_image_loss.backward()\n",
        "\n",
        "    recon_kspace_batch = RF(netG(zf_recon_batch)[1], batch_mask, batch = True) #Because same underlying image\n",
        "    g_freq_loss = alpha*criterionG_freq(recon_kspace_batch,us_kspace_batch)\n",
        "    G_loss_freq.append(g_freq_loss)\n",
        "    g_freq_loss.backward()\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    g_loss_total = adv_g_loss+g_image_loss#+g_freq_loss\n",
        "    G_loss_total.append(g_loss_total)\n",
        "\n",
        "    opt_G.step()   \n",
        "\n",
        "  # print(\"Epoch:\", epoch, \"G Loss:\", float('%.2f' % g_loss_total.data.tolist()), \"D Loss:\", float('%.2f' % d_loss_total.data.tolist()))\n",
        "\n",
        "  # if epoch%25==0:\n",
        "  #   clear_output(wait=True)\n",
        "  G_loss_adv_epoch = sum(G_loss_adv[-batch_size:])\n",
        "  G_loss_img_epoch = sum(G_loss_img[-batch_size:])\n",
        "  G_loss_freq_epoch = sum(G_loss_freq[-batch_size:])\n",
        "  print(\"G_loss_adv_epoch:\", float('%.2f' % G_loss_adv_epoch.data.tolist()), \"G_loss_img_epoch:\", float('%.2f' % G_loss_img_epoch.data.tolist()), \"G_loss_freq_epoch:\", float('%.2f' % G_loss_freq_epoch.data.tolist()))\n",
        "\n",
        "  if epoch%5>=0:\n",
        "    disp_img = recon_image_batch[0].cpu().detach().numpy()\n",
        "    disp_img = np.clip(disp_img, -1, 1)\n",
        "    disp_img2 = full_image_batch[0].cpu().detach().numpy()\n",
        "    disp_img3 = zf_recon_batch[0].cpu().detach().numpy()\n",
        "    \n",
        "    displayTensor(disp_img2)\n",
        "    plt.show()\n",
        "    displayTensor(disp_img3)\n",
        "    plt.show()\n",
        "    displayTensor(disp_img)\n",
        "    plt.show()\n",
        "    # print(recon_image_batch.size())\n",
        "\n",
        "  image_recon.append(disp_img)\n",
        "  # loss_arr.append(g_image_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0MVXzW4EfGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"Wasserstein Loss Training\"\n",
        "image_recon=[]\n",
        "loss_arr=[]\n",
        "print(device)\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, im_tuple in enumerate(dataloader, 0):\n",
        "\n",
        "    full_image_batch = im_tuple[0]\n",
        "    # print(device)\n",
        "    full_image_batch = full_image_batch.to(device)\n",
        "    print(full_image_batch.dtype)\n",
        "    # us_kspace_batch = im_tuple[1]\n",
        "    us_kspace_batch = us_kspace_batch.to(device)\n",
        "    zf_recon_batch = im_tuple[2]\n",
        "    zf_recon_batch = zf_recon_batch.to(device)\n",
        "\n",
        "    \n",
        "    # recon_image_batch = netG(torch.ifft(mask*torch.fft(full_image_batch.permute([0,2,3,1]),2)).permute([0,3,1,2]))[1]\n",
        "    # recon_kspace_batch = (mask*torch.fft(netG(torch.ifft(us_kspace_batch.permute([0,2,3,1]),2).permute([0,3,1,2]))[1].permute([0,2,3,1]),2)).permute([0,3,1,2])\n",
        "    # recon_image_batch = netG(FhRh(RF(full_image_batch, batch_mask, batch = True), batch = True))[0]\n",
        "    # recon_kspace_batch = RF(netG(FhRh(us_kspace_batch, batch=True))[0], batch_mask, batch = True)\n",
        "    \n",
        "    \n",
        "    #Discriminator Training \n",
        "    # real_targets = torch.full([batch_size], real_label, device=device)\n",
        "    # fake_targets = torch.full([batch_size], real_label, device=device)\n",
        "    for _ in range(5):\n",
        "      opt_D.zero_grad()#Different mini batches for real and fake targets\n",
        "      \n",
        "      real_logits = netD(full_image_batch).view(-1)\n",
        "      real_d_loss = -1*torch.mean(real_logits)\n",
        "      D_loss_real.append(real_d_loss)\n",
        "      real_d_loss.backward()\n",
        "\n",
        "      gen_full_image_batch = netG(zf_recon_batch)[1]\n",
        "      fake_logitsD = netD(gen_full_image_batch.detach()).view(-1)\n",
        "      fake_d_loss = torch.mean(fake_logitsD)\n",
        "      D_loss_fake.append(fake_d_loss)\n",
        "      fake_d_loss.backward()\n",
        "\n",
        "      # with torch.no_grad():\n",
        "      d_loss_total = real_d_loss+fake_d_loss\n",
        "      D_loss_total.append(d_loss_total.data)\n",
        "\n",
        "      opt_D.step()\n",
        "\n",
        "      for p in netD.parameters():\n",
        "        p.data.clamp_(-0.02, 0.02)\n",
        "\n",
        "    #Generator Training\n",
        "    # real_targets = torch.full([batch_size], real_label, device=device)\n",
        "    # fake_targets = torch.full([batch_size], real_label, device=device)\n",
        "    opt_G.zero_grad()\n",
        "\n",
        "    fake_logitsG = netD(gen_full_image_batch).view(-1)\n",
        "    adv_g_loss = -1*torch.mean(fake_logitsG)\n",
        "    G_loss_adv.append(adv_g_loss)\n",
        "    adv_g_loss.backward()\n",
        "\n",
        "    recon_image_batch = netG(zf_recon_batch)[1] #Because same underlying image\n",
        "    g_image_loss = gamma*criterionG_image(recon_image_batch,full_image_batch)\n",
        "    G_loss_img.append(g_image_loss)\n",
        "    g_image_loss.backward()\n",
        "\n",
        "    recon_kspace_batch = RF(netG(zf_recon_batch)[1], batch_mask, batch = True) #Because same underlying image\n",
        "    g_freq_loss = alpha*criterionG_freq(recon_kspace_batch,us_kspace_batch)\n",
        "    G_loss_freq.append(g_freq_loss)\n",
        "    g_freq_loss.backward()\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    g_loss_total = adv_g_loss#+g_image_loss#+g_freq_loss\n",
        "    G_loss_total.append(g_loss_total)\n",
        "\n",
        "    opt_G.step()   \n",
        "\n",
        "  # print(\"Epoch:\", epoch, \"G Loss:\", float('%.2f' % g_loss_total.data.tolist()), \"D Loss:\", float('%.2f' % d_loss_total.data.tolist()))\n",
        "\n",
        "  # if epoch%25==0:\n",
        "  #   clear_output(wait=True)\n",
        "  G_loss_adv_epoch = sum(G_loss_adv[-batch_size:])\n",
        "  G_loss_img_epoch = sum(G_loss_img[-batch_size:])\n",
        "  G_loss_freq_epoch = sum(G_loss_freq[-batch_size:])\n",
        "  print(\"G_loss_adv_epoch:\", float('%.2f' % G_loss_adv_epoch.data.tolist()), \"G_loss_img_epoch:\", float('%.2f' % G_loss_img_epoch.data.tolist()), \"G_loss_freq_epoch:\", float('%.2f' % G_loss_freq_epoch.data.tolist()))\n",
        "\n",
        "  if epoch%5==0:\n",
        "    disp_img = gen_full_image_batch[0].cpu().detach().numpy()\n",
        "    disp_img = np.clip(disp_img, -1, 1)\n",
        "    disp_img2 = full_image_batch[0].cpu().detach().numpy()\n",
        "    disp_img3 = zf_recon_batch[0].cpu().detach().numpy()\n",
        "    \n",
        "    displayTensor(disp_img2)\n",
        "    plt.show()\n",
        "    displayTensor(disp_img3)\n",
        "    plt.show()\n",
        "    displayTensor(disp_img)\n",
        "    plt.show()\n",
        "    # print(recon_image_batch.size())\n",
        "\n",
        "  image_recon.append(disp_img)\n",
        "  # loss_arr.append(g_image_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECR3yHJhr9Hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ae63ac57-8765-408a-b96a-72d655dda2c9"
      },
      "source": [
        "plt.plot(D_loss_total)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f112817cb70>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAFR8jkIttN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(disp_img)\n",
        "disp_img = np.clip(disp_img, -1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzp8xsUd9yTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displayTensor(disp_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01_Os5D--Y4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}